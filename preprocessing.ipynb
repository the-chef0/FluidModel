{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/\"\n",
    "subsets = [d for d in listdir(dataset_path)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Resizing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_RES = (1920,1090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I ONLY RAN THIS ONCE TO RESIZE EVERYTHING TO THE SAME RES - DO NOT RUN AGAIN\n",
    "LEFT IT HERE ONLY FOR REFERENCE\n",
    "\n",
    "subset_index = 0\n",
    "\n",
    "for dir_name in subsets:\n",
    "    \n",
    "    subset_path = dataset_path + dir_name + \"/\"\n",
    "    subset_files = [f for f in listdir(subset_path) if isfile(join(subset_path, f))]\n",
    "    subset_files.sort()\n",
    "    \n",
    "    for filename in subset_files:\n",
    "        file_path = subset_path + filename\n",
    "        image = Image.open(file_path)\n",
    "        if not image.size == TARGET_RES:\n",
    "            image = image.resize(TARGET_RES)\n",
    "            image.save(file_path[:-4] + \"_resized.png\")\n",
    "\n",
    "    print(\"Processed subset \" + str(subset_index + 1) + \"/\" + str(len(subsets)) )\n",
    "    subset_index += 1\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Processing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_RECTANGLE = (610, 190, 1300, 900)\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_crop_images():\n",
    "    '''\n",
    "    returns:\n",
    "        images_unnormalized: List of lists \"subset\":\n",
    "            subset: List of tuples \"(image, label)\" containing one set of the exercise\n",
    "                image: Numpy array with ultrasound image resized and cropped to a fixed size and area\n",
    "                label: Integer from 0 to 4 indicating the fatigue class\n",
    "                       where the fatigue class indicates the number of reps that the muscle\n",
    "                       has been exposed to. The number of reps is divided into roughly equal\n",
    "                       fatigue classes of approximately size n, the first n reps belong to\n",
    "                       fatigue class 0, the next n reps to fatigue class 1 etc.\n",
    "                       It will be easier for a neural net to predict a fatigue class\n",
    "                       than a specific rep number.\n",
    "        baseline_brightness_per_subset: Average grey value across first images in each subset\n",
    "        num_images: total number of images\n",
    "    '''\n",
    "    # Keeps mean pixel brightness of the first image in every subset\n",
    "    baseline_brightness_per_subset = np.zeros(len(subsets))\n",
    "    images_unnormalized = []\n",
    "\n",
    "    subset_index = 0\n",
    "    num_images = 0\n",
    "    for dir_name in subsets:\n",
    "        # Directory level bookkeeping\n",
    "        subset_path = dataset_path + dir_name + \"/\"\n",
    "        subset_files = [f for f in listdir(subset_path) if isfile(join(subset_path, f))]\n",
    "        # Filenames correspond to the order in which the images were taken so\n",
    "        # higher number in file name -> more reps done on the muscle\n",
    "        # We sort to keep them in the rep order\n",
    "        subset_files.sort()\n",
    "        # Calculating reps per fatigue class\n",
    "        num_files_in_subset = len(subset_files)\n",
    "        class_modulus = np.ceil(num_files_in_subset / NUM_CLASSES)\n",
    "        \n",
    "        subset_images_unnormalized = []\n",
    "\n",
    "        file_in_subset_index = 0\n",
    "        for filename in subset_files:\n",
    "            # Path to the file\n",
    "            file_path = subset_path + filename\n",
    "            image = Image.open(file_path)\n",
    "            num_images += 1\n",
    "            # Cropping the padding away\n",
    "            image = image.crop(CROP_RECTANGLE)\n",
    "            # Convert to grayscale so that the resulting numpy array doesn't have 3 RGB channels\n",
    "            image = image.convert(\"L\")\n",
    "            # Converting to numpy array for normalization later\n",
    "            image_as_array = np.asarray(image)\n",
    "\n",
    "            if (file_in_subset_index == 0):\n",
    "                # If the file is the first one in the subset, compute the mean brightness\n",
    "                baseline_brightness_per_subset[subset_index] = np.floor(image_as_array.mean())\n",
    "\n",
    "            # Label and add to return array\n",
    "            label = np.floor(file_in_subset_index / class_modulus)\n",
    "            subset_images_unnormalized.append((image_as_array, label))\n",
    "\n",
    "            file_in_subset_index += 1\n",
    "\n",
    "        images_unnormalized.append(subset_images_unnormalized)\n",
    "        print(\"Processed subset \" + str(subset_index + 1) + \"/\" + str(len(subsets)) )\n",
    "        subset_index += 1\n",
    "\n",
    "    return images_unnormalized, baseline_brightness_per_subset.mean(), num_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Normalization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 710\n",
    "IMAGE_HEIGHT = 690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images, baseline_brightness, num_images):\n",
    "    '''\n",
    "    returns:\n",
    "        X_data: Array of length num_images of arrays \"flattened_image\"\n",
    "            flattened_image: Array of length IMAGE_WIDTH * IMAGE_HEIGHT\n",
    "                             containing flattened, normalized image pixels.\n",
    "                             Normalization is done by adding modifier_i to the first image\n",
    "                             of set i such that the average grey values of all first images are\n",
    "                             approximately equal. modifier_i is also added to all other images\n",
    "                             in set i to preserve relative brightness differences.\n",
    "        y_data: Array of length num_images of arrays \"label\"\n",
    "            label: Array of length NUM_CLASSES such that y_data[i] is the\n",
    "                   label for X_data[i], with label[j] == 1 if X_data[i]\n",
    "                   is labeled j and 0 otherwise.\n",
    "    '''\n",
    "    X_data = np.zeros((num_images, IMAGE_WIDTH * IMAGE_HEIGHT))\n",
    "    y_data = np.zeros((num_images, NUM_CLASSES))\n",
    "\n",
    "    subset_index = 0\n",
    "    absolute_image_index = 0\n",
    "    for subset in images:\n",
    "        relative_image_index = 0\n",
    "        brightness_modifier = 0\n",
    "        \n",
    "        for image_label_tuple in subset:\n",
    "            image = image_label_tuple[0]\n",
    "            label = int(image_label_tuple[1])\n",
    "            \n",
    "            # If this is the first image in the set, compute a new brightness modifier\n",
    "            if (relative_image_index == 0):\n",
    "                brightness_modifier = baseline_brightness - image.mean()\n",
    "\n",
    "            image_normalized = image + brightness_modifier\n",
    "            X_data[absolute_image_index] = image_normalized.flatten()\n",
    "            y_data[absolute_image_index][label] = 1\n",
    "            \n",
    "            relative_image_index += 1\n",
    "            absolute_image_index += 1\n",
    "\n",
    "        subset_index += 1\n",
    "\n",
    "    return X_data, y_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Main </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed subset 1/20\n",
      "Processed subset 2/20\n",
      "Processed subset 3/20\n",
      "Processed subset 4/20\n",
      "Processed subset 5/20\n",
      "Processed subset 6/20\n",
      "Processed subset 7/20\n",
      "Processed subset 8/20\n",
      "Processed subset 9/20\n",
      "Processed subset 10/20\n",
      "Processed subset 11/20\n",
      "Processed subset 12/20\n",
      "Processed subset 13/20\n",
      "Processed subset 14/20\n",
      "Processed subset 15/20\n",
      "Processed subset 16/20\n",
      "Processed subset 17/20\n",
      "Processed subset 18/20\n",
      "Processed subset 19/20\n",
      "Processed subset 20/20\n"
     ]
    }
   ],
   "source": [
    "images, baseline_brightness, num_images = load_and_crop_images()\n",
    "X,y = normalize_images(images, baseline_brightness, num_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
